{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e8ca0b-2e9c-4884-8d26-a1cdf557a9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-10-24 16:46:35.974141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-24 16:46:36.197612: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-24 16:46:37.275159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-10-24 16:46:37.275327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-10-24 16:46:37.275336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tqdm\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6533324-85cf-4079-a104-d20a981f6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(input_file_path):\n",
    "    data = []\n",
    "\n",
    "    with open(input_file_path) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "58fc9b90-51ea-463b-87d1-128d5ad44cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(output_file_path, data):\n",
    "    # Open a new JSON file for writing\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        for data_line in data:\n",
    "            output_file.write(json.dumps(data_line) + \"\\n\")\n",
    "\n",
    "    print(f\"Data with 'Test' property added has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae87b0ef-e953-4e00-ac30-890583a094dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(\"./squad_data_train_pos_ner.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd7cba63-71a8-43cf-a764-1e9e2bf4eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_position(text, pos_context, answer, context):\n",
    "    sentence = Sentence(text)\n",
    "    tokens = []\n",
    "    spaces_no = context[:answer].count(\" \")\n",
    "\n",
    "    for word in sentence:\n",
    "        tokens.append(word.text)\n",
    "\n",
    "    start_position = 0\n",
    "    token_number = 0\n",
    "    match = False\n",
    "    no_match = -1\n",
    "    for start_position in range(len(pos_context) - len(tokens)):\n",
    "        k_words_context = [list(line.values())[0][0] for line in\n",
    "                      pos_context[start_position:start_position + len(tokens)]]\n",
    "        next_word = [list(line.values())[0][0] for line in\n",
    "                      pos_context[start_position + len(tokens):start_position + len(tokens) + 1]]\n",
    "        if k_words_context == tokens and (token_number + spaces_no == answer or token_number + spaces_no + 1 == answer):\n",
    "            match = True\n",
    "            break\n",
    "\n",
    "        if (token_number + spaces_no == answer):\n",
    "            no_match = start_position\n",
    "            break\n",
    "        elif next_word == ' ' and token_number + spaces_no + 1 == answer:\n",
    "            no_match = start_position\n",
    "            break\n",
    "\n",
    "        token_number += len(k_words_context[0])\n",
    "    if match:\n",
    "        return start_position\n",
    "    return no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c4de604-25c5-43f3-8a4b-0ba0836ddf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_characters = [\"$\", \",\", \"''\", \"-LRB-\", \"-RRB-\", \".\", \":\", \"``\"]\n",
    "\n",
    "\n",
    "def get_proc_pos_between_item(pos_context, context, answers):\n",
    "    positions = {}\n",
    "    copy_answer = []\n",
    "    i = 0\n",
    "    for answer in answers[\"answer_start\"]:\n",
    "        answer_position = find_start_position(answers[\"text\"][i], pos_context, answer, context)\n",
    "        if answer_position != -1:\n",
    "            positions[answer_position] = answers[\"answer_start\"][i]\n",
    "            copy_answer.append(answers[\"answer_start\"][i])\n",
    "        i += 1\n",
    "    pos = \"\"\n",
    "    offset = 0\n",
    "    offsets = {}\n",
    "    for index in range(len(pos_context)):\n",
    "        pos_text = pos_context[index][str(index)]\n",
    "\n",
    "        if pos_text[1] in special_characters:\n",
    "            pos_text[1] = \"sym\"\n",
    "        if index in positions.keys():\n",
    "            offsets[positions[index]] = offset\n",
    "        pos += f\"{pos_text[0]} [{pos_text[1].lower()}] \"\n",
    "        offset += len(f\" [{pos_text[1]}] \")\n",
    "\n",
    "    answer_starts = []\n",
    "\n",
    "    for index in range(len(copy_answer)):\n",
    "        answer = copy_answer[index]\n",
    "        spaces_no = context[:answer].count(\" \") + 1\n",
    "        answer += offsets[answer] - spaces_no\n",
    "        if pos[answer : answer + 1] == \" \":\n",
    "            answer += 1\n",
    "        answer_starts.append(answer)\n",
    "\n",
    "    return pos, answer_starts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3417a4c-78be-44f2-bde4-cede73a22d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The [dt] Review [nnp] of [in] Politics [nnp] was [vbd] founded [vbn] in [in] 1939 [cd] by [in] Gurian [nnp] , [sym] modeled [vbn] after [in] German [jj] Catholic [jj] journals [nns] . [sym] It [prp] quickly [rb] emerged [vbd] as [in] part [nn] of [in] an [dt] international [jj] Catholic [jj] intellectual [jj] revival [nn] , [sym] offering [vbg] an [dt] alternative [jj] vision [nn] to [in] positivist [jj] philosophy [nn] . [sym] For [in] 44 [cd] years [nns] , [sym] the [dt] Review [nnp] was [vbd] edited [vbn] by [in] Gurian [nnp] , [sym] Matthew [nnp] Fitzsimons [nnp] , [sym] Frederick [nnp] Crosson [nnp] , [sym] and [cc] Thomas [nnp] Stritch [nnp] . [sym] Intellectual [jj] leaders [nns] included [vbd] Gurian [nnp] , [sym] Jacques [nnp] Maritain [nnp] , [sym] Frank [nnp] O'Malley [nnp] , [sym] Leo [nnp] Richard [nnp] Ward [nnp] , [sym] F. [nnp] A. [nnp] Hermens [nnp] , [sym] and [cc] John [nnp] U. [nnp] Nef [nnp] . [sym] It [prp] became [vbd] a [dt] major [jj] forum [nn] for [in] political [jj] ideas [nns] and [cc] modern [jj] political [jj] concerns [nns] , [sym] especially [rb] from [in] a [dt] Catholic [jj] and [cc] scholastic [jj] tradition [nn] . [sym] \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_id = 65\n",
    "\n",
    "pos, answer_starts = get_proc_pos_between_item(data[example_id]['POS_context'], data[example_id]['context'],\n",
    "                          data[example_id]['answers'])\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db67f36b-bc91-4862-9595-96f239066f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:33<00:00, 2650.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm.tqdm(data):\n",
    "    context = item['context']\n",
    "    question = item['question']\n",
    "    item['context'], item['answers']['answer_start'] = get_proc_pos_between_item(item['POS_context'], context, item['answers'])\n",
    "\n",
    "    item.pop('POS_context', None)\n",
    "    item.pop('POS_question', None)\n",
    "    item.pop('NER_question', None)\n",
    "    item.pop('NER_context', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bbf7901c-ebc4-4eeb-acdf-c05dc8a82d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'Test' property added has been saved to ./squad_data_train_pos_ner_2.json\n"
     ]
    }
   ],
   "source": [
    "write_data(\"./squad_data_train_pos_ner_2.json\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "86266d76-7aa2-43fe-8e61-a76289dfbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = read_data('./squad_data_validation_pos_between.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "515b8a84-f894-4433-b5c2-2d7d1669f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_answer(context, answers):\n",
    "    new_answers = []\n",
    "    if len(answers['answer_start']) == 0:\n",
    "        return\n",
    "\n",
    "    for index, answer in enumerate(answers['text']):\n",
    "        new_answer = ''\n",
    "        if len(answers['answer_start']) < index + 1:\n",
    "            return new_answers\n",
    "        answer_start = answers['answer_start'][index]\n",
    "        if answer_start != -1:\n",
    "            tokenized_context = Sentence(context[answer_start:])\n",
    "            no_of_words = len(Sentence(answer))\n",
    "            max_length = no_of_words * 4\n",
    "            if max_length > len(tokenized_context):\n",
    "                max_length = len(tokenized_context)\n",
    "            for token_index in range(max_length):\n",
    "                if tokenized_context[token_index].text == '[' or (len(tokenized_context) > token_index+1 and tokenized_context[token_index+1].text == ']') or token_index == no_of_words * 4 - 1:\n",
    "                    new_answer += tokenized_context[token_index].text\n",
    "                else:\n",
    "                    new_answer += tokenized_context[token_index].text + ' '\n",
    "        new_answers.append(new_answer)\n",
    "    return new_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c75fcb27-e8cf-4951-bfe0-33133336a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = 632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c7ad2f3d-c5bb-4c45-a6bd-ec33adb2b9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence[96]: \"the [dt] Patriots [nnps] , [sym] Dallas [nnp] Cowboys [nnps] , [sym] and [cc] Pittsburgh [nnp] Steelers [nnps] as [in] one [cd] of [in] four [cd] teams [nns] that [wdt] have [vbp] made [vbn] eight [cd] appearances [nns] in [in] the [dt] Super [nnp] Bowl [nnp] . [sym]\""
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentence(proc_data[example_id]['context'][1083:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3e71958a-15dc-45d0-8994-61804ab97df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['pre-game and halftime coverage.',\n",
       "  'halftime',\n",
       "  'anchor the pre-game and halftime coverage'],\n",
       " 'answer_start': [487, 443]}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data[example_id]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b9de6e1d-817f-4a8d-8028-e30b65562bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['halftime [nn] coverage [nn] . [sym] ', 'anchor [vb]']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_updated_answer(proc_data[example_id]['context'], proc_data[example_id]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "41636afb-407f-423a-9827-99823de52d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [01:48<00:00, 97.08it/s] \n"
     ]
    }
   ],
   "source": [
    "for item in tqdm.tqdm(proc_data):\n",
    "    item['answers']['text'] = get_updated_answer(item['context'], item['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "984c5f6d-ef63-4dd3-a664-f1d06e6c26a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['halftime [nn] coverage [nn] . [sym] ', 'anchor [vb]'],\n",
       " 'answer_start': [487, 443]}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data[example_id]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c4fdc6ac-65fb-4c8e-8ab8-58ce5a86a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'Test' property added has been saved to ./squad_data_validation_pos_ner_answer_updated.json\n"
     ]
    }
   ],
   "source": [
    "write_data(\"./squad_data_validation_pos_ner_answer_updated.json\", proc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b126a5-8deb-4467-8a91-a4b3fe2dd04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
