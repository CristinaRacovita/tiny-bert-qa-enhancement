{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e8ca0b-2e9c-4884-8d26-a1cdf557a9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-10-29 09:40:20.946787: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-29 09:40:21.194324: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-29 09:40:22.294704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-10-29 09:40:22.294869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-10-29 09:40:22.294877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tqdm\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6533324-85cf-4079-a104-d20a981f6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(input_file_path):\n",
    "    data = []\n",
    "\n",
    "    with open(input_file_path) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fc9b90-51ea-463b-87d1-128d5ad44cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(output_file_path, data):\n",
    "    # Open a new JSON file for writing\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        for data_line in data:\n",
    "            output_file.write(json.dumps(data_line) + \"\\n\")\n",
    "\n",
    "    print(f\"Data with 'Test' property added has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ae87b0ef-e953-4e00-ac30-890583a094dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(\"./squad_data_train_pos_ner.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "4232297f-f49b-4f17-9fe9-5c04c6960153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subustring_in_string(string, substring, symbol):\n",
    "    # print(string, symbol, symbol in string and substring in string)\n",
    "    return symbol in string and substring in string\n",
    "\n",
    "\n",
    "def is_one_text_in_context(text, context):\n",
    "    if context.count(text+' ') +  context.count(text+'.') > 1:\n",
    "        return False\n",
    "    # print(text, context.count(text+' '), context.count(text+'-'), context.count(text+'.'))\n",
    "    return context.count(text+' ') == 1 or context.count(text+'-') == 1 or context.count(text+'.') == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "cd7cba63-71a8-43cf-a764-1e9e2bf4eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_position(text, pos_context, answer, context):\n",
    "    # print(text)\n",
    "    sentence = Sentence(text)\n",
    "    tokens = []\n",
    "    spaces_no = context[:answer].count(\" \")\n",
    "    # pos_context = pos_context.replace('\\\\','')\n",
    "\n",
    "    for word in sentence:\n",
    "        tokens.append(word.text)\n",
    "    # print(tokens)\n",
    "\n",
    "    start_position = 0\n",
    "    token_number = 0\n",
    "    match = False\n",
    "    no_match = -1\n",
    "    unicode = False\n",
    "    # print(context.count(text))\n",
    "    one_apperance = is_one_text_in_context(text, context)\n",
    "    # print(one_apperance)\n",
    "    for start_position in range(len(pos_context) - len(tokens) + 1):\n",
    "        k_words_context_ = [bytes(list(line.values())[0][0], \"utf-8\").decode(\"unicode_escape\") for line in\n",
    "                      pos_context[start_position:start_position + len(tokens)]]\n",
    "        k_words_context = [list(line.values())[0][0].replace('\\\\','') for line in\n",
    "                      pos_context[start_position:start_position + len(tokens)]]\n",
    "        next_word = [list(line.values())[0][0] for line in\n",
    "                      pos_context[start_position + len(tokens):start_position + len(tokens) + 1]]\n",
    "        # print(k_words_context, tokens, token_number + spaces_no)\n",
    "        k_words_context_string = \" \".join(k_words_context)\n",
    "        if context.count(text) == 1 and k_words_context == tokens:\n",
    "            match = True\n",
    "            break\n",
    "\n",
    "        if one_apperance and (k_words_context == tokens or is_subustring_in_string(k_words_context_string, text, '-') or is_subustring_in_string(k_words_context_string, text, '.')):\n",
    "            # print(text, is_one_text_in_context(text, context), \" \".join(tokens),  \" \".join(k_words_context), token_number + spaces_no)\n",
    "            match = True\n",
    "            break\n",
    "\n",
    "        if text in k_words_context_string and (token_number + spaces_no == answer or token_number + spaces_no + 1 == answer):\n",
    "            match = True\n",
    "            break\n",
    "\n",
    "        # if (token_number + spaces_no == answer):\n",
    "        #     no_match = start_position\n",
    "        #     print('HI 1')\n",
    "        #     break\n",
    "        elif next_word == ' ' and token_number + spaces_no + 1 == answer:\n",
    "            no_match = start_position\n",
    "            break\n",
    "        if \"'\" in k_words_context_:\n",
    "            token_number += len(k_words_context_[0]) + 1\n",
    "        else:\n",
    "            token_number += len(k_words_context_[0])\n",
    "    if match:\n",
    "        return start_position\n",
    "    return no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b70b823d-ba38-4c9d-8f36-4f75782ac550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Dreamgirls'], 'answer_start': [260]}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem = 292\n",
    "data[elem][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "b3bcf3a9-f1e9-414b-9262-af7e3f98e613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Following the disbandment of Destiny\\'s Child in June 2005, she released her second solo album, B\\'Day (2006), which contained hits \"Déjà Vu\", \"Irreplaceable\", and \"Beautiful Liar\". Beyoncé also ventured into acting, with a Golden Globe-nominated performance in Dreamgirls (2006), and starring roles in The Pink Panther (2006) and Obsessed (2009). Her marriage to rapper Jay Z and portrayal of Etta James in Cadillac Records (2008) influenced her third album, I Am... Sasha Fierce (2008), which saw the birth of her alter-ego Sasha Fierce and earned a record-setting six Grammy Awards in 2010, including Song of the Year for \"Single Ladies (Put a Ring on It)\". Beyoncé took a hiatus from music in 2010 and took over management of her career; her fourth album 4 (2011) was subsequently mellower in tone, exploring 1970s funk, 1980s pop, and 1990s soul. Her critically acclaimed fifth studio album, Beyoncé (2013), was distinguished from previous releases by its experimental production and exploration of darker themes.'"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[elem][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4ae799bf-d943-43db-ac1a-5f19b617264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = find_start_position(data[elem][\"answers\"][\"text\"][0],data[elem][\"POS_context\"], data[elem][\"answers\"][\"answer_start\"][0], data[elem][\"context\"])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "eaefe7ab-5f4a-4564-9a24-c41396fe68f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dreamgirls', 'NNPS']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[elem]['POS_context'][index][str(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "9c4de604-25c5-43f3-8a4b-0ba0836ddf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_characters = [\"$\", \",\", \"''\", \"-LRB-\", \"-RRB-\", \".\", \":\", \"``\"]\n",
    "\n",
    "\n",
    "def get_proc_pos_between_item(pos_context, context, answers):\n",
    "    positions = {}\n",
    "    copy_answer = []\n",
    "    i = 0\n",
    "    # answers[\"answer_start\"].sort()\n",
    "    # answers[\"answer_start\"].sort()\n",
    "    \n",
    "    for answer in answers[\"answer_start\"]:\n",
    "        answer_position = find_start_position(answers[\"text\"][i], pos_context, answer, context)\n",
    "        if answer_position != -1:\n",
    "            positions[answer_position] = answers[\"answer_start\"][i]\n",
    "            copy_answer.append(answers[\"answer_start\"][i])\n",
    "        i += 1\n",
    "    pos = \"\"\n",
    "    offset = 0\n",
    "    offsets = {}\n",
    "    # print(positions)\n",
    "    for index in range(len(pos_context)):\n",
    "        pos_text = pos_context[index][str(index)]\n",
    "\n",
    "        if pos_text[1] in special_characters:\n",
    "            pos_text[1] = \"sym\"\n",
    "        if index in positions.keys():\n",
    "            offsets[positions[index]] = offset\n",
    "        pos += f\"{pos_text[0]} [{pos_text[1].lower()}] \"\n",
    "        offset += len(f\" [{pos_text[1]}] \")\n",
    "\n",
    "    answer_starts = []\n",
    "    # print(copy_answer)\n",
    "    for index in range(len(copy_answer)):\n",
    "        answer = copy_answer[index]\n",
    "        if answer == 0:\n",
    "            answer_starts.append(answer)\n",
    "            continue\n",
    "        spaces_no = context[:answer].count(\" \") + 1\n",
    "        if answer not in offsets.keys():\n",
    "            continue\n",
    "        else:\n",
    "            answer += offsets[answer] - spaces_no\n",
    "        if pos[answer : answer + 1] == \" \":\n",
    "            answer += 1\n",
    "        # if len(answers[\"text\"]) > index:\n",
    "        #     if len(answers[\"text\"][index]) > 1:\n",
    "        #         if pos[answer][0] == answers[\"text\"][index][1]:\n",
    "        #             answer -= 1\n",
    "        answer_starts.append(answer)\n",
    "\n",
    "    return pos, answer_starts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "b3417a4c-78be-44f2-bde4-cede73a22d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The [dt] university [nn] is [vbz] affiliated [vbn] with [in] the [dt] Congregation [nnp] of [in] Holy [nnp] Cross [nnp] ( [sym] Latin [nnp] : [sym] Congregatio [nnp] a [dt] Sancta [nnp] Cruce [nnp] , [sym] abbreviated [vbn] postnominals [nns] : [sym] \" [sym] CSC [nnp] \") [sym] . [sym] While [in] religious [jj] affiliation [nn] is [vbz] not [rb] a [dt] criterion [nn] for [in] admission [nn] , [sym] more [jjr] than [in] 93 [cd] % [nn] of [in] students [nns] identify [vbp] as [in] Christian [nnp] , [sym] with [in] over [in] 80 [cd] % [nn] of [in] the [dt] total [nn] being [vbg] Catholic [jj] . [sym] Collectively [rb] , [sym] Catholic [nnp] Mass [nnp] is [vbz] celebrated [vbn] over [in] 100 [cd] times [nns] per [in] week [nn] on [in] campus [nn] , [sym] and [cc] a [dt] large [jj] campus [nn] ministry [nn] program [nn] provides [vbz] for [in] the [dt] faith [nn] needs [nns] of [in] the [dt] community [nn] . [sym] There [ex] are [vbp] multitudes [nns] of [in] religious [jj] statues [nns] and [cc] artwork [nn] around [in] campus [nn] , [sym] most [rbs] prominent [jj] of [in] which [wdt] are [vbp] the [dt] statue [nn] of [in] Mary [nnp] on [in] the [dt] Main [nnp] Building [nnp] , [sym] the [dt] Notre [nnp] Dame [nnp] Grotto [nnp] , [sym] and [cc] the [dt] Word [nnp] of [in] Life [nnp] mural [nn] on [in] Hesburgh [nnp] Library [nnp] depicting [vbg] Christ [nnp] as [in] a [dt] teacher [nn] . [sym] Additionally [rb] , [sym] every [dt] classroom [nn] displays [vbz] a [dt] crucifix [nn] . [sym] There [ex] are [vbp] many [jj] religious [jj] clubs [nns] ( [sym] catholic [jj] and [cc] non-Catholic [jj] ) [sym] at [in] the [dt] school [nn] , [sym] including [vbg] Council [nnp] # [nn] 1477 [cd] of [in] the [dt] Knights [nnps] of [in] Columbus [nnp] ( [sym] KOC [nnp] ) [sym] , [sym] Baptist [nnp] Collegiate [nnp] Ministry [nnp] ( [sym] BCM [nnp] ) [sym] , [sym] Jewish [nnp] Club [nnp] , [sym] Muslim [nnp] Student [nnp] Association [nnp] , [sym] Orthodox [nnp] Christian [nnp] Fellowship [nnp] , [sym] The [dt] Mormon [nnp] Club [nnp] , [sym] and [cc] many [jj] more [jjr] . [sym] The [dt] Notre [nnp] Dame [nnp] KofC [nnp] are [vbp] known [vbn] for [in] being [vbg] the [dt] first [jj] collegiate [jj] council [nn] of [in] KofC [nnp] , [sym] operating [vbg] a [dt] charitable [jj] concession [nn] stand [nn] during [in] every [dt] home [nn] football [nn] game [nn] and [cc] owning [vbg] their [prp$] own [jj] building [nn] on [in] campus [nn] which [wdt] can [md] be [vb] used [vbn] as [in] a [dt] cigar [nn] lounge [nn] . [sym] Fifty-seven [cd] chapels [nns] are [vbp] located [vbn] throughout [in] the [dt] campus [nn] . [sym] ',\n",
       " [401])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_id = 84\n",
    "\n",
    "pos, answer_starts = get_proc_pos_between_item(data[example_id]['POS_context'], data[example_id]['context'],\n",
    "                          data[example_id]['answers'])\n",
    "pos, answer_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "11cd0935-040d-40da-a6ce-b46ad41d570e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[dt] total [nn] being [vbg] Catholic [jj] . [sym] Collectively [rb] , [sym] Catholic [nnp] Mass [nnp] is [vbz] celebrated [vbn] over [in] 100 [cd] times [nns] per [in] week [nn] on [in] campus [nn] , [sym] and [cc] a [dt] large [jj] campus [nn] ministry [nn] program [nn] provides [vbz] for [in] the [dt] faith [nn] needs [nns] of [in] the [dt] community [nn] . [sym] There [ex] are [vbp] multitudes [nns] of [in] religious [jj] statues [nns] and [cc] artwork [nn] around [in] campus [nn] , [sym] most [rbs] prominent [jj] of [in] which [wdt] are [vbp] the [dt] statue [nn] of [in] Mary [nnp] on [in] the [dt] Main [nnp] Building [nnp] , [sym] the [dt] Notre [nnp] Dame [nnp] Grotto [nnp] , [sym] and [cc] the [dt] Word [nnp] of [in] Life [nnp] mural [nn] on [in] Hesburgh [nnp] Library [nnp] depicting [vbg] Christ [nnp] as [in] a [dt] teacher [nn] . [sym] Additionally [rb] , [sym] every [dt] classroom [nn] displays [vbz] a [dt] crucifix [nn] . [sym] There [ex] are [vbp] many [jj] religious [jj] clubs [nns] ( [sym] catholic [jj] and [cc] non-Catholic [jj] ) [sym] at [in] the [dt] school [nn] , [sym] including [vbg] Council [nnp] # [nn] 1477 [cd] of [in] the [dt] Knights [nnps] of [in] Columbus [nnp] ( [sym] KOC [nnp] ) [sym] , [sym] Baptist [nnp] Collegiate [nnp] Ministry [nnp] ( [sym] BCM [nnp] ) [sym] , [sym] Jewish [nnp] Club [nnp] , [sym] Muslim [nnp] Student [nnp] Association [nnp] , [sym] Orthodox [nnp] Christian [nnp] Fellowship [nnp] , [sym] The [dt] Mormon [nnp] Club [nnp] , [sym] and [cc] many [jj] more [jjr] . [sym] The [dt] Notre [nnp] Dame [nnp] KofC [nnp] are [vbp] known [vbn] for [in] being [vbg] the [dt] first [jj] collegiate [jj] council [nn] of [in] KofC [nnp] , [sym] operating [vbg] a [dt] charitable [jj] concession [nn] stand [nn] during [in] every [dt] home [nn] football [nn] game [nn] and [cc] owning [vbg] their [prp$] own [jj] building [nn] on [in] campus [nn] which [wdt] can [md] be [vb] used [vbn] as [in] a [dt] cigar [nn] lounge [nn] . [sym] Fifty-seven [cd] chapels [nns] are [vbp] located [vbn] throughout [in] the [dt] campus [nn] . [sym] '"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[554:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "db67f36b-bc91-4862-9595-96f239066f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [01:00<00:00, 1458.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm.tqdm(data):\n",
    "    context = item['context']\n",
    "    question = item['question']\n",
    "    item['context'], item['answers']['answer_start'] = get_proc_pos_between_item(item['POS_context'], context, item['answers'])\n",
    "\n",
    "    item.pop('POS_context', None)\n",
    "    item.pop('POS_question', None)\n",
    "    item.pop('NER_question', None)\n",
    "    item.pop('NER_context', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "0f2c6656-d151-4d15-8b87-9011e1ea9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87599it [00:00, 183267.93it/s]\n"
     ]
    }
   ],
   "source": [
    "incorrect_answers_no = 0\n",
    "\n",
    "for index, line in tqdm.tqdm(enumerate(data)):\n",
    "    try:\n",
    "        if len(line[\"answers\"][\"answer_start\"]) == 0:\n",
    "            continue\n",
    "        answer_start = line[\"answers\"][\"answer_start\"][0]\n",
    "        answer = line[\"answers\"][\"text\"][0]\n",
    "\n",
    "        if answer_start == -1:\n",
    "            continue\n",
    "\n",
    "        if line[\"context\"][answer_start:][0] != answer[0]:\n",
    "            # line[\"answers\"][\"answer_start\"][0] -= 1\n",
    "            incorrect_answers_no += 1\n",
    "            #print(index, line[\"context\"][answer_start:], 4*'-', answer, answer_start)\n",
    "\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "5e364173-9cb6-4ab6-8572-ecdaca87d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87599it [00:00, 270431.26it/s]\n"
     ]
    }
   ],
   "source": [
    "incorrect_answers_no = 0\n",
    "\n",
    "for i, line in tqdm.tqdm(enumerate(data)):\n",
    "    try:\n",
    "        if(len(line[\"answers\"][\"answer_start\"]) == 0):\n",
    "            line[\"answers\"][\"answer_start\"].append(0)\n",
    "        answer_start = line[\"answers\"][\"answer_start\"][0]\n",
    "        answer =  line[\"answers\"][\"text\"][0]\n",
    "        answer_length = len(answer)\n",
    "\n",
    "        if line[\"context\"][answer_start:][0] != answer[0]:\n",
    "            incorrect_answers_no += 1\n",
    "\n",
    "    except Exception as e: \n",
    "        # print(e)\n",
    "        incorrect_answers_no += 1\n",
    "        # print(i, answer_start, line[\"context\"][answer_start:], 4*'-', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "b1ee8d9d-b1ab-4651-8b79-67d3aec3089b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56bf6e823aeaaa14008c9627',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Following [vbg] the [dt] disbandment [nn] of [in] Destiny [nnp] \\'s [pos] Child [nnp] in [in] June [nnp] 2005 [cd] , [sym] she [prp] released [vbd] her [prp$] second [jj] solo [jj] album [nn] , [sym] B\\'Day [nnp] ( [sym] 2006 [cd] ) [sym] , [sym] which [wdt] contained [vbd] hits [nns] \" [sym] Déjà [nnp] Vu [nnp] \" [sym] , [sym] \" [sym] Irreplaceable [nnp] \" [sym] , [sym] and [cc] \" [sym] Beautiful [nnp] Liar [nnp] \" [sym] . [sym] Beyoncé [nnp] also [rb] ventured [vbd] into [in] acting [nn] , [sym] with [in] a [dt] Golden [nnp] Globe-nominated [nnp] performance [nn] in [in] Dreamgirls [nnps] ( [sym] 2006 [cd] ) [sym] , [sym] and [cc] starring [vbg] roles [nns] in [in] The [dt] Pink [nnp] Panther [nnp] ( [sym] 2006 [cd] ) [sym] and [cc] Obsessed [nnp] ( [sym] 2009 [cd] ) [sym] . [sym] Her [prp$] marriage [nn] to [in] rapper [nn] Jay [nnp] Z [nnp] and [cc] portrayal [nn] of [in] Etta [nnp] James [nnp] in [in] Cadillac [nnp] Records [nnps] ( [sym] 2008 [cd] ) [sym] influenced [vbd] her [prp$] third [jj] album [nn] , [sym] I [prp] Am [vbp] ... [sym] Sasha [nnp] Fierce [nnp] ( [sym] 2008 [cd] ) [sym] , [sym] which [wdt] saw [vbd] the [dt] birth [nn] of [in] her [prp$] alter-ego [nn] Sasha [nnp] Fierce [nnp] and [cc] earned [vbd] a [dt] record-setting [vbg] six [cd] Grammy [nnp] Awards [nnps] in [in] 2010 [cd] , [sym] including [vbg] Song [nnp] of [in] the [dt] Year [nnp] for [in] \" [sym] Single [nnp] Ladies [nnps] ( [sym] Put [vb] a [dt] Ring [nnp] on [in] It [prp] )\" [sym] . [sym] Beyoncé [nnp] took [vbd] a [dt] hiatus [nn] from [in] music [nn] in [in] 2010 [cd] and [cc] took [vbd] over [rp] management [nn] of [in] her [prp$] career [nn] ; [sym] her [prp$] fourth [jj] album [nn] 4 [cd] ( [sym] 2011 [cd] ) [sym] was [vbd] subsequently [rb] mellower [jjr] in [in] tone [nn] , [sym] exploring [vbg] 1970s [nns] funk [nn] , [sym] 1980s [nns] pop [nn] , [sym] and [cc] 1990s [nns] soul [nn] . [sym] Her [prp$] critically [rb] acclaimed [vbn] fifth [jj] studio [nn] album [nn] , [sym] Beyoncé [nnp] ( [sym] 2013 [cd] ) [sym] , [sym] was [vbd] distinguished [vbn] from [in] previous [jj] releases [nns] by [in] its [prp$] experimental [jj] production [nn] and [cc] exploration [nn] of [in] darker [jjr] themes [nns] . [sym] ',\n",
       " 'question': 'For what movie did Beyonce receive  her first Golden Globe nomination?',\n",
       " 'answers': {'text': ['Dreamgirls'], 'answer_start': [578]}}"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "0190cd21-8470-4a6d-ad5d-9da8794d6333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2390"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_answers_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "bbf7901c-ebc4-4eeb-acdf-c05dc8a82d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'Test' property added has been saved to ./squad_data_validation_pos_between.json\n"
     ]
    }
   ],
   "source": [
    "write_data(\"./squad_data_validation_pos_between.json\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "86266d76-7aa2-43fe-8e61-a76289dfbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = read_data('./squad_data_validation_pos_between.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "60a6fffe-eaff-41a2-877b-a1fe305eb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rreplace(string, substring, replacement):\n",
    "    k = string.rfind(substring)\n",
    "    return string[:k] + replacement + string[k+len(substring):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "515b8a84-f894-4433-b5c2-2d7d1669f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\"'\", '.', ',', ')']\n",
    "\n",
    "\n",
    "def get_updated_answer(context, answers):\n",
    "    new_answers = []\n",
    "    if len(answers['answer_start']) == 0:\n",
    "        return\n",
    "\n",
    "    for index, answer in enumerate(answers['text']):\n",
    "        new_answer = ''\n",
    "        if len(answers['answer_start']) < index + 1:\n",
    "            return new_answers\n",
    "        answer_start = answers['answer_start'][index]\n",
    "        if answer_start != -1:\n",
    "            tokenized_context = Sentence(context[answer_start:])\n",
    "            no_of_words = len(Sentence(answer))\n",
    "            max_length = no_of_words * 3 + no_of_words\n",
    "            if max_length > len(tokenized_context):\n",
    "                max_length = len(tokenized_context)\n",
    "            minus_words = 0\n",
    "            for token_index in range(max_length):\n",
    "                # if token_index == max_length - minus_words - 1:\n",
    "                #     break\n",
    "                if (tokenized_context[token_index].text == '[' and tokenized_context[token_index+1].text != '[') or (len(tokenized_context) > token_index+1 and tokenized_context[token_index].text!=']' and tokenized_context[token_index+1].text==']') or token_index == no_of_words * 4 - 1:\n",
    "                    new_answer += tokenized_context[token_index].text\n",
    "                elif tokenized_context[token_index].text in symbols and tokenized_context[token_index+1].text != '[':\n",
    "                    new_answer += tokenized_context[token_index].text\n",
    "                elif (tokenized_context[token_index].text.replace('.', '').isalpha() or tokenized_context[token_index].text[-1] in '.\"') and tokenized_context[token_index+1].text in '.$]':\n",
    "                    new_answer += tokenized_context[token_index].text\n",
    "                    # minus_words += 1\n",
    "                elif len(tokenized_context) > token_index+1 and tokenized_context[token_index].text.replace('.', '').isnumeric() and tokenized_context[token_index+1].text in '.$]':\n",
    "                    new_answer += tokenized_context[token_index].text\n",
    "                elif tokenized_context[token_index].text.replace('-', '').isalpha() and tokenized_context[token_index+1].text in '.$]':\n",
    "                    new_answer += tokenized_context[token_index].text\n",
    "                elif len(tokenized_context) > token_index+1 and tokenized_context[token_index+1].text[0].isnumeric() and tokenized_context[token_index].text in '-':\n",
    "                    new_answer += tokenized_context[token_index].text\n",
    "                else:\n",
    "                    new_answer += tokenized_context[token_index].text + ' '\n",
    "        new_answer = new_answer.rstrip()\n",
    "        if answer_start != -1:\n",
    "            tokens_new_answer = Sentence(new_answer)\n",
    "            # print(tokens_new_answer[-2])\n",
    "            if tokens_new_answer[-2].text == '[':\n",
    "                # print(tokens_new_answer[-2])\n",
    "                new_answer += ']'\n",
    "            if tokens_new_answer[-1].text == '[':\n",
    "                #print(tokens_new_answer[-1], tokens_new_answer[-2].text)\n",
    "                new_answer = rreplace(new_answer, tokens_new_answer[-1].text, '')\n",
    "                new_answer = rreplace(new_answer, tokens_new_answer[-2].text, '')\n",
    "                new_answer = new_answer.rstrip()\n",
    "        new_answers.append(new_answer)\n",
    "    return new_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "c75fcb27-e8cf-4951-bfe0-33133336a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = 4892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b9de6e1d-817f-4a8d-8028-e30b65562bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a [dt] U.S. [nnp] inventor [nn] , [sym] engineer [nn] and [cc] solar [jj] energy [nn] pioneer [nn]']"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_updated_answer(proc_data[example_id]['context'], proc_data[example_id]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41636afb-407f-423a-9827-99823de52d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 81573/87599 [03:34<00:16, 362.93it/s]"
     ]
    }
   ],
   "source": [
    "for item in tqdm.tqdm(proc_data):\n",
    "    item['answers']['text'] = get_updated_answer(item['context'], item['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "19b126a5-8deb-4467-8a91-a4b3fe2dd04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10570it [00:00, 284819.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717 :28 [cd]  ---- : 28 [cd]\n",
      "3615 oxygen-18. [nn]  ---- oxygen-18 . [nn]\n",
      "4006 -Gemini [jj]  ---- - Gemini [jj]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "incorrect_answers_no = 0\n",
    "\n",
    "for index, line in tqdm.tqdm(enumerate(proc_data)):\n",
    "    try:\n",
    "        if len(line[\"answers\"][\"text\"]) == 0:\n",
    "            line[\"answers\"][\"text\"] = ['']\n",
    "        if len(line[\"answers\"][\"answer_start\"]) == 0:\n",
    "            line[\"answers\"][\"text\"] = [0]\n",
    "        answer_start = line[\"answers\"][\"answer_start\"][0]\n",
    "        answer = line[\"answers\"][\"text\"][0]\n",
    "        answer_length = len(answer)\n",
    "\n",
    "        if answer_start == -1:\n",
    "            continue\n",
    "\n",
    "        if line[\"context\"][answer_start: answer_start + answer_length] != answer:\n",
    "            incorrect_answers_no += 1\n",
    "            print(index, line[\"context\"][answer_start: answer_start + answer_length],\n",
    "                  \"-\" * 4, answer)\n",
    "\n",
    "        # if answer[-1] != ']':\n",
    "        #     print(index, line[\"context\"][answer_start: answer_start + answer_length], \"-\" * 4, answer)\n",
    "        #     incorrect_answers_no += 1\n",
    "\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "2132257a-5271-4437-b54e-86578735ea8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028382213812677387"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_answers_no / len(proc_data) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "c4fdc6ac-65fb-4c8e-8ab8-58ce5a86a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'Test' property added has been saved to ./squad_data_validation_pos_ner_answer_updated.json\n"
     ]
    }
   ],
   "source": [
    "write_data(\"./squad_data_train_pos_ner_answer_updated.json\", proc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae7e07-e001-4780-bbf9-e87fd2ce6c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
